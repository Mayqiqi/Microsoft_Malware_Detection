# Welcome to your new notebook
# Type here in the cell editor to add code!

# ! pip install pyspark==3.4
# ! pip install synapse
# ! pip install synapseML
import pyspark
from synapse.ml.lightgbm import LightGBMClassifier
from synapse.ml.lightgbm import LightGBMClassificationModel
from pyspark.sql.functions import col
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator
# 初始化 Spark
spark = pyspark.sql.SparkSession.builder.appName("MyApp") \
            .config("spark.jars.packages", "com.microsoft.azure:synapseml_2.12:1.0.2") \
            .getOrCreate()


# read data
# train_data1 = spark.read.parquet("Microsoft_Malware_Detection/data/clean_train_data.parquet")
train_data = spark.read.parquet("../data/clean_train_data_LGBM.parquet")
test_data = spark.read.parquet("../data/clean_test_data_LGBM.parquet")
data_for_local_test = spark.read.parquet("../data/data_for_local_test_LGBM.parquet")
# train_data.drop("Census_ActivationChannel")
# rename columns to make sure LGBM works properly


# List of columns to rename
# columns_to_rename = train_data.columns  # Adjust this list to include only the problematic columns
# print("columns_to_rename:",(columns_to_rename))

# # Function to replace special characters in column names
# def clean_column_name(column_name):
#     for char in [" ", ",", ":", "\\", "[", "]", "{", "}"]:
#         column_name = column_name.replace(char, "_")
#     return column_name

# # Rename the columns
# for col_name in columns_to_rename:
#     train_data = train_data.withColumnRenamed(col_name, clean_column_name(col_name))
#     test_data = test_data.withColumnRenamed(col_name, clean_column_name(col_name))
#     data_for_local_test = data_for_local_test.withColumnRenamed(col_name, clean_column_name(col_name))

# Assuming 'features' is your assembled features vector
# assembler = VectorAssembler(inputCols=[clean_column_name(c) for c in columns_to_rename], outputCol="features")
# train_data = assembler.transform(train_data)
# test_data = assembler.transform(test_data)
# data_for_local_test = assembler.transform(data_for_local_test)

# config LightGBM classifier
lgbm = LightGBMClassifier(
    featuresCol='features',
    labelCol='HasDetections', # 替换 'label' 为你的标签列名称
    objective='binary', # 根据你的需求选择适当的目标（例如 'binary' 或 'multiclass'）
    numIterations=100,
    learningRate=0.2
)
# train
train_data.show()
# train_data1.show()
model = lgbm.fit(train_data)
# predict
predictions = model.transform(test_data)
# save
predictions.show()
model.write().save("../models/lightGBM_model")
predictions = predictions.select("MachineIdentifier", "prediction")
final_predictions = predictions.withColumnRenamed("prediction", "HasDetections")

final_predictions.coalesce(1).write.csv("../submissions/lightGBM_model_prediction.csv", header=True)

# test logistic model performance
local_test_predictions = model.transform(data_for_local_test)

# Calculate ROC
evaluator = BinaryClassificationEvaluator(labelCol="HasDetections", rawPredictionCol="prediction", metricName="areaUnderROC")
auc = evaluator.evaluate(local_test_predictions)
print("Test Area Under ROC: " + str(auc))


# Calculate Accuracy
accuracy_evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="accuracy")
accuracy = accuracy_evaluator.evaluate(local_test_predictions)
print("Accuracy: %g" % accuracy)


# Calculate F1 Score
f1_evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="f1")
f1_score = f1_evaluator.evaluate(local_test_predictions)
print("F1 Score: %g" % f1_score)

# 关闭 Spark 会话
spark.stop()