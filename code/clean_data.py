from pyspark.ml import Pipeline
from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.sql.types import StringType, DoubleType, IntegerType
from pyspark.sql.functions import col, count, when
from pyspark.ml.regression import LinearRegression
from pyspark import SparkConf, SparkContext
from pyspark.sql.functions import col, when
from pyspark.ml.evaluation import RegressionEvaluator


# 初始化 Spark Session
from pyspark.sql import SparkSession

# 创建SparkSession，并设置所有需要的配置
spark = SparkSession.builder.appName("MalwarePrediction") \
    .config("spark.executor.memory", "10g") \
    .config("spark.memory.fraction", "0.6") \
    .config("spark.memory.storageFraction", "0.5") \
    .config("spark.driver.memory", "8g") \
    .config("spark.executor.cores", "6") \
    .config("spark.kryoserializer.buffer.max", "1g") \
    .getOrCreate()


# 加载数据
# train_data = spark.read.csv("../data/train.csv", header=True, inferSchema=True)
# test_data = spark.read.csv("../data/test.csv", header=True, inferSchema=True)

train_data = spark.read.parquet("../data/no_null_train_data.parquet")
test_data = spark.read.parquet("../data/no_null_test_data.parquet")

# train_data, data_for_local_test = train_data.randomSplit([0.8, 0.2])
# train_data = train_data.repartition(100)


column_dtypes = {
    "MachineIdentifier":                                    StringType(),
    "ProductName":                                          StringType(),
    "EngineVersion":                                        StringType(),
    "AppVersion":                                           StringType(),
    "AvSigVersion":                                         StringType(),
    "IsBeta":                                               IntegerType(),
    "RtpStateBitfield":                                     IntegerType(),
    "IsSxsPassiveMode":                                     IntegerType(),
    "AVProductStatesIdentifier":                            IntegerType(),
    'AVProductsInstalled':                                  IntegerType(),
    'AVProductsEnabled':                                    IntegerType(),
    'HasTpm':                                               IntegerType(),
    'CountryIdentifier':                                    IntegerType(),
    'CityIdentifier':                                       IntegerType(),
    'OrganizationIdentifier':                               IntegerType(),
    'GeoNameIdentifier':                                    IntegerType(),
    'LocaleEnglishNameIdentifier':                          IntegerType(),
    'Platform':                                             StringType(),
    'Processor':                                            StringType(),
    'OsVer':                                                StringType(),
    'OsBuild':                                              IntegerType(),
    'OsSuite':                                              IntegerType(),
    'OsPlatformSubRelease':                                 StringType(),
    'OsBuildLab':                                           StringType(),
    'SkuEdition':                                           StringType(),
    'IsProtected':                                          IntegerType(),
    'AutoSampleOptIn':                                      IntegerType(),
    'SMode':                                                IntegerType(),
    'IeVerIdentifier':                                      IntegerType(),
    'SmartScreen':                                          StringType(),
    'Firewall':                                             IntegerType(),
    'UacLuaenable':                                         IntegerType(),
    'Census_MDC2FormFactor':                                StringType(),
    'Census_DeviceFamily':                                  StringType(),
    'Census_OEMNameIdentifier':                             IntegerType(),
    'Census_OEMModelIdentifier':                            IntegerType(),
    'Census_ProcessorCoreCount':                            IntegerType(),

    'Census_ProcessorManufacturerIdentifier':               IntegerType(),
    'Census_ProcessorModelIdentifier':                      IntegerType(),
    'Census_PrimaryDiskTotalCapacity':                      IntegerType(),
    'Census_PrimaryDiskTypeName':                           StringType(),
    'Census_SystemVolumeTotalCapacity':                     IntegerType(),
    'Census_HasOpticalDiskDrive':                           IntegerType(),
    'Census_TotalPhysicalRAM':                              IntegerType(),
    'Census_ChassisTypeName':                               StringType(),
    'Census_InternalPrimaryDiagonalDisplaySizeInInches':    IntegerType(),
    'Census_InternalPrimaryDisplayResolutionHorizontal':    IntegerType(),
    'Census_InternalPrimaryDisplayResolutionVertical':      IntegerType(),
    'Census_PowerPlatformRoleName':                         StringType(),
    'Census_InternalBatteryNumberOfCharges':                IntegerType(),
    'Census_OSVersion':                                     StringType(),
    'Census_OSArchitecture':                                StringType(),
    'Census_OSBranch':                                      StringType(),
    'Census_OSBuildNumber':                                 IntegerType(),
    'Census_OSBuildRevision':                               IntegerType(),
    'Census_OSEdition':                                     StringType(),
    'Census_OSSkuName':                                     StringType(),
    'Census_OSInstallTypeName':                             StringType(),
    'Census_OSInstallLanguageIdentifier':                   IntegerType(),
    'Census_OSUILocaleIdentifier':                          IntegerType(),
    'Census_OSWUAutoUpdateOptionsName':                     StringType(),
    'Census_IsPortableOperatingSystem':                     IntegerType(),
    'Census_GenuineStateName':                              StringType(),
    'Census_ActivationChannel':                             StringType(),
    'Census_IsFlightsDisabled':                             IntegerType(),
    'Census_FlightRing':                                    StringType(),
    'Census_FirmwareManufacturerIdentifier':                IntegerType(),
    'Census_FirmwareVersionIdentifier':                     IntegerType(),
    'Census_IsSecureBootEnabled':                           IntegerType(),
    'Census_IsVirtualDevice':                               IntegerType(),
    'Census_IsTouchEnabled':                                IntegerType(),
    'Census_IsPenCapable':                                  IntegerType(),
    'Census_IsAlwaysOnAlwaysConnectedCapable':              IntegerType(),
    'Wdft_IsGamer':                                         IntegerType(),
    'Wdft_RegionIdentifier':                                IntegerType(),

}



for column, column_type in column_dtypes.items():
    train_data = train_data.withColumn(column, col(column).cast(column_type))
    test_data = test_data.withColumn(column, col(column).cast(column_type))
    if column_type == StringType():
        train_data = train_data.na.fill({column: "unknown"})
        test_data = test_data.na.fill("unknown")
    elif column_type == DoubleType():
        train_data = train_data.na.fill({column: 0.00})
        test_data = test_data.na.fill({column: 0.00})
    elif column_type == IntegerType():
        train_data = train_data.na.fill({column: 0})
        test_data = test_data.na.fill({column: 0})

train_data, data_for_local_test = train_data.randomSplit([0.8, 0.2])
train_data = train_data.repartition(100)
test_data = test_data.repartition(100)
train_data.withColumn("HasDetections", col("HasDetections").cast(IntegerType()))
data_for_local_test.withColumn("HasDetections", col("HasDetections").cast(IntegerType()))


numeric_cols = []
categorical_columns = []
for column, dtype in column_dtypes.items():
    if column == "MachineIdentifier":
        continue
    if isinstance(dtype, StringType):
        categorical_columns.append(column)
    elif isinstance(dtype, IntegerType):
        numeric_cols.append(column)





batch_size = 3
for i in range(0, len(categorical_columns), batch_size):
    batch_columns = categorical_columns[i:i + batch_size]

    # 为每个批次的分类列创建索引和编码的转换器
    # indexers = [StringIndexer(inputCol=c, outputCol=c + "_indexed", handleInvalid='keep') for c in batch_columns]
    # encoders = [OneHotEncoder(inputCol=c + "_indexed", outputCol=c + "_encoded") for c in batch_columns]
    stages = []
    for c in batch_columns:
        stringIndexer = StringIndexer(inputCol=c, outputCol=c + "_index",
                                      handleInvalid='keep')
        encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[c + "_ohe"])
        stages += [stringIndexer, encoder]

    # 构建Pipeline
    # stages = indexers + encoders
    pipeline = Pipeline(stages=stages)

    # 应用Pipeline到数据集
    pipeline_model = pipeline.fit(train_data)
    train_data = pipeline_model.transform(train_data)
    data_for_local_test = pipeline_model.transform(data_for_local_test)
    test_data = pipeline_model.transform(test_data)

# 创建特征向量
assembler_inputs = [c + "_ohe" for c in categorical_columns] + numeric_cols
assembler = VectorAssembler(inputCols=assembler_inputs, outputCol="features")

# 应用VectorAssembler到数据集
train_data = assembler.transform(train_data)
data_for_local_test = assembler.transform(data_for_local_test)
test_data = assembler.transform(test_data)

train_data.write.parquet("../data/clean_train_data.parquet")
test_data.write.parquet("../data/clean_test_data.parquet")
data_for_local_test.write.parquet("../data/data_for_local_test.parquet")


# lr = LinearRegression(featuresCol="features", labelCol="HasDetections")
# lr_model = lr.fit(train_data)
# predictions = lr_model.transform(test_data)

# predictions = predictions.select("MachineIdentifier", "prediction", "HasDetections")
# predictions = predictions.withColumn("binary_prediction", when(col("prediction") >= 0.5, 1).otherwise(0).cast(DoubleType()))
# predictions.show()

# lr_model.write().save("../models/linear_model")












#
#
# grouped_categorical_columns = [categorical_columns[i:i+10] for i in range(0, len(categorical_columns), 10)]
# transformed_dfs = []
#
#
# for group in grouped_categorical_columns:
#     stages = []
#     for c in group:
#         # 为每个列创建StringIndexer和OneHotEncoder
#         indexer = StringIndexer(inputCol=c, outputCol=c+"_indexed").setHandleInvalid("skip")
#         encoder = OneHotEncoder(inputCols=[c+"_indexed"], outputCols=[c+"_encoded"])
#         stages += [indexer, encoder]
#
#     # 创建Pipeline
#     pipeline = Pipeline(stages=stages)
#
#     # Fit并转换数据
#     df_transformed = pipeline.fit(train_data).transform(train_data)
#
#     # 选择原始列和新的编码列
#     selected_cols = [col(c) for c in train_data.columns] + [col(c+"_encoded") for c in group]
#     df_transformed = df_transformed.select(*selected_cols)
#
#     # 将转换后的DataFrame添加到列表
#     transformed_dfs.append(df_transformed)
#
# train_data_combined = train_data.select(numeric_cols)
#
#
# for df_transformed in transformed_dfs:
#     train_data_combined = train_data_combined.join(df_transformed, numeric_cols, "inner")
#
# # 添加VectorAssembler到Pipeline
# assemblerInputs = [c + "_classVec" for c in categorical_columns] + numeric_cols
# assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")
# pipeline = Pipeline(stages=[assembler])
#
# # 应用Pipeline
# df_final = pipeline.fit(train_data_combined).transform(train_data_combined)







# stages = []
# for categorical_col in categorical_columns:
#     stringIndexer = StringIndexer(inputCol=categorical_col, outputCol=categorical_col + "_index", handleInvalid='keep')
#     encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categorical_col + "_ohe"])
#     stages += [stringIndexer, encoder]
#
# assemblerInputs = [c + "_ohe" for c in categorical_columns] + numeric_cols
# assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")
# stages += [assembler]
#
#
# pipeline = Pipeline(stages=stages)
#
# pipelineModel = pipeline.fit(train_data)
# df_train_transformed = pipelineModel.transform(train_data)
# # df_test_transformed = pipelineModel.transform(test_data)
# df_data_for_local_test_transformed = pipelineModel.transform(data_for_local_test)



# df_train_transformed.write.parquet("Malware_Detection/data/clean_train_data.parquet")
# df_test_transformed.write.parquet("Malware_Detection/clean_test_data.parquet")
#
# lr = LinearRegression(featuresCol="features", labelCol="HasDetections")
# lr_model = lr.fit(df_train_transformed)
# # predictions = lr_model.transform(df_test_transformed)
#
# predictions = lr_model.transform(df_data_for_local_test_transformed)
#
# # lr_model.write().save("../models/linear_model")
#
# predictions = predictions.select("MachineIdentifier", "prediction", "HasDetections")
# predictions = predictions.withColumn("binary_prediction", when(col("prediction") >= 0.5, 1).otherwise(0))
# # final_predictions = predictions.withColumnRenamed("binary_prediction", "HasDetections")
# # final_predictions = final_predictions.select("MachineIdentifier", "HasDetections")
# # final_predictions.show()
# predictions.show()
#
# # final_predictions.coalesce(1).write.csv("../submissions/linear_model_prediction.csv", header=True, mode="overwrite")


# # 初始化评估器并计算 MSE 和 RMSE
# evaluator = RegressionEvaluator(labelCol="HasDetections", predictionCol="prediction", metricName="mse")
# mse = evaluator.evaluate(predictions)
# print("Mean Squared Error (MSE) on test data = %g" % mse)



spark.stop()
