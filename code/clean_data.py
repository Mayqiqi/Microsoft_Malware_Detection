from pyspark.ml import Pipeline
from pyspark.sql import SparkSession
from pyspark.sql.functions import when
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.sql.types import StringType, DoubleType, IntegerType
from pyspark.sql.functions import col
from pyspark.ml.regression import LinearRegression

# 初始化 Spark Session
spark = SparkSession.builder.appName("MalwarePrediction") \
    .config("spark.executor.memory", "6g") \
    .config("spark.memory.fraction", "0.6") \
    .config("spark.memory.storageFraction", "0.5") \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.cores", "2") \
    .getOrCreate()

# 加载数据
train_data = spark.read.csv("../data/train.csv", header=True, inferSchema=True)
test_data = spark.read.csv("../data/test.csv", header=True, inferSchema=True)

selected_columns = [
    "MachineIdentifier", "ProductName", "EngineVersion", "AvSigVersion", "IsProtected",
    "Platform", "OsVer", "OsBuild", "OsSuite", "OsPlatformSubRelease",
    "Processor", "Census_ProcessorCoreCount", "Census_TotalPhysicalRAM",
    "Census_PrimaryDiskTotalCapacity", "Census_SystemVolumeTotalCapacity",
    "Firewall", "Census_IsVirtualDevice", "Census_IsTouchEnabled",
    "HasDetections"  # 目标列
]

train_data = train_data.select(selected_columns)
test_data = test_data.select(selected_columns[:-1])

print(train_data.dtypes)
train_data.show()

column_dtypes = {
    "MachineIdentifier": StringType(),
    "ProductName": StringType(),
    "EngineVersion": StringType(),
    "AvSigVersion": StringType(),
    "IsProtected": IntegerType(),
    "Platform": StringType(),
    "OsVer": StringType(),
    "OsBuild": IntegerType(),
    "OsSuite": IntegerType(),
    "OsPlatformSubRelease": StringType(),
    "Processor": StringType(),
    "Census_ProcessorCoreCount": IntegerType(),
    "Census_TotalPhysicalRAM": IntegerType(),
    "Census_PrimaryDiskTotalCapacity": DoubleType(),
    "Census_SystemVolumeTotalCapacity": IntegerType(),
    "Firewall": IntegerType(),
    "Census_IsVirtualDevice": IntegerType(),
    "Census_IsTouchEnabled": IntegerType()
}

for column, column_type in column_dtypes.items():
    train_data = train_data.withColumn(column, col(column).cast(column_type))
    test_data = test_data.withColumn(column, col(column).cast(column_type))
    if column_type == StringType():
        train_data = train_data.na.fill({column: "unknown"})
        test_data = test_data.na.fill("unkown")
    elif column_type == DoubleType():
        train_data = train_data.na.fill({column: 0.00})
        test_data = test_data.na.fill({column: 0.00})
    elif column_type == IntegerType():
        train_data = train_data.na.fill({column: 0})
        test_data = test_data.na.fill({column: 0})

train_data.withColumn("HasDetections", col("HasDetections").cast(IntegerType()))

numeric_cols = ["IsProtected", "OsBuild", "OsSuite", "Census_ProcessorCoreCount", "Census_TotalPhysicalRAM",
                "Census_PrimaryDiskTotalCapacity", "Firewall", "Census_IsVirtualDevice", "Census_IsTouchEnabled"]

categorical_columns = ["ProductName", "EngineVersion", "AvSigVersion", "Platform", "OsVer", "OsPlatformSubRelease",
                       "Processor"]

stages = []
for categorical_col in categorical_columns:
    stringIndexer = StringIndexer(inputCol=categorical_col, outputCol=categorical_col + "_index", handleInvalid='keep')
    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categorical_col + "_ohe"])
    stages += [stringIndexer, encoder]

assemblerInputs = [c + "_ohe" for c in categorical_columns] + numeric_cols
assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")
stages += [assembler]


pipeline = Pipeline(stages=stages)

pipelineModel = pipeline.fit(train_data)
df_train_transformed = pipelineModel.transform(train_data)
df_test_transformed = pipelineModel.transform(test_data)

# df_train_transformed.write.parquet("Malware_Detection/data/clean_train_data.parquet")
# df_test_transformed.write.parquet("Malware_Detection/clean_test_data.parquet")

lr = LinearRegression(featuresCol="features", labelCol="HasDetections")
lr_model = lr.fit(df_train_transformed)
predictions = lr_model.transform(df_test_transformed)

# lr_model.write().save("../models/linear_model")

predictions = predictions.select("MachineIdentifier", "prediction")
predictions = predictions.withColumn("binary_prediction", when(col("prediction") >= 0.5, 1).otherwise(0))
final_predictions = predictions.withColumnRenamed("binary_prediction", "HasDetections")
final_predictions = final_predictions.select("MachineIdentifier", "HasDetections")
final_predictions.show()

# final_predictions.coalesce(1).write.csv("../submissions/linear_model_prediction.csv", header=True, mode="overwrite")

spark.stop()
